# RAG Query - Project Summary

## ğŸ¯ What You Have

A **production-ready, Docker-containerized RAG pipeline** for legal document retrieval that runs on AWS EC2 with GPU support.

---

## ğŸ“¦ Complete File List

**All files located in**: `rag-query/` directory

### Core Python Files (9)
```
âœ“ rag-query/api.py               - Flask REST API (returns JSON to frontend)
âœ“ rag-query/config.py            - Configuration & environment variables
âœ“ rag-query/models.py            - LLM & reranker initialization
âœ“ rag-query/filters.py           - Filter processing utilities
âœ“ rag-query/retrieval.py         - Pinecone retrieval (baseline & hybrid)
âœ“ rag-query/llm_generation.py    - LLM response generation
âœ“ rag-query/utils.py             - Utility functions
âœ“ rag-query/pipeline.py          - Main pipeline orchestration
âœ“ rag-query/main.py              - CLI entry point
```

### Docker Files (6)
```
âœ“ rag-query/Dockerfile             - Container image definition
âœ“ rag-query/docker-compose.yml     - Container orchestration
âœ“ rag-query/.dockerignore          - Build optimization
âœ“ rag-query/build.sh               - Build automation script
âœ“ rag-query/run.sh                 - Run automation script
âœ“ rag-query/.env.example           - Environment template
```

### Documentation (5)
```
âœ“ rag-query/README.md                    - Complete documentation
âœ“ rag-query/EC2_SETUP.md                 - Detailed EC2 guide
âœ“ rag-query/QUICKSTART.md                - 5-minute deployment
âœ“ rag-query/DEPLOYMENT_CHECKLIST.md      - Step-by-step checklist
âœ“ rag-query/PROJECT_SUMMARY.md           - This file
```

### Configuration Files (3)
```
âœ“ rag-query/requirements.txt       - Python dependencies
âœ“ rag-query/example_query.json     - Example query format
âœ“ rag-query/.gitignore             - Git exclusions
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AWS EC2 GPU Instance                  â”‚
â”‚                         (g4dn.xlarge)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Docker Container                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         RAG Pipeline Application                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   LLaMA 3.1  â”‚    â”‚  Reranker    â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   8B Model   â”‚    â”‚   Model      â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚           â”‚                  â”‚                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                    â”‚                             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚   Pipeline Core     â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Retrieval        â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Filtering        â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Generation       â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                    â”‚                             â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                       â”‚                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                     â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                 â”‚  outputs/ dir   â”‚                           â”‚
â”‚                 â”‚  (Volume Mount) â”‚                           â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Pinecone Vector DB  â”‚
              â”‚  (Cloud - External)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Deployment Flow

```
1. GitHub Push
   â”‚
   â–¼
2. Clone on EC2
   â”‚
   â–¼
3. Navigate to rag-query/
   â”‚
   â–¼
4. Set .env Variables
   â”‚
   â–¼
5. Build Docker Image (./build.sh)
   â”‚
   â–¼
6. Run Container (./run.sh or docker compose up)
   â”‚
   â–¼
7. Models Download (First run only - ~16GB)
   â”‚
   â–¼
8. Flask API Ready on port 8000! âœ“
   â”‚
   â–¼
9. Test: curl http://localhost:8000/health
```

---

## ğŸ® Usage Modes

### API Mode (Recommended - Returns JSON)
```bash
cd rag-query

# Start the Flask API server
docker compose up -d

# Query via API (returns JSON)
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are dog walking regulations?",
    "filters": {
      "locations": [{"state": "ca", "county": ["alameda-county"]}]
    },
    "mode": "hybrid"
  }'
```
**Output**: JSON response with `response` and `chunks` fields

### CLI Mode (For Testing - Can save to CSV)
```bash
cd rag-query

# Baseline search
python main.py --mode baseline --example

# Hybrid search
python main.py --mode hybrid --example

# Filter-only search
python main.py --mode hybrid --json queries/filter_only.json
```
**Note**: CLI mode can generate CSV files if enabled in pipeline.py (currently disabled)

---

## ğŸ“Š Input/Output

### API Input (POST /query)
```json
{
  "query": "Are dogs allowed in public parks?",
  "filters": {
    "locations": [
      {"state": "ca", "county": ["alameda-county"]}]
    ],
    "penalty": "Y"
  },
  "mode": "hybrid"
}
```

### API Output (JSON)
```json
{
  "response": "Based on the retrieved legal documents, dogs are allowed in public parks in Alameda County with the following restrictions...",
  "chunks": [
    {
      "id": "chunk_123",
      "score": 0.856,
      "rerank_score": 0.923,
      "state": "ca",
      "county": "alameda-county",
      "section": "Chapter 6.04.010",
      "chunk_text": "Full legal text of the regulation...",
      "penalty": "Y",
      "obligation": "Y",
      "permission": "N",
      "prohibition": "Y",
      "fk_grade": 12.5,
      "fre": 45.2,
      "wc": 250,
      "pct_complex": 35.8
    }
  ],
  "mode": "hybrid"
}
```

**Frontend can convert `chunks` array to CSV/DataFrame for display and download**

---

## ğŸ’° Cost Breakdown

### EC2 Costs (g4dn.xlarge in us-east-1)
- **On-Demand**: ~$0.526/hour
- **24/7 Monthly**: ~$379.22
- **8 hours/day**: ~$126.41/month
- **Spot Instance**: 60-70% cheaper!

### API Costs
- **Pinecone**: Varies by usage (check your plan)
- **Hugging Face**: Free (you host the model)

**Cost-Saving Tips:**
1. Stop instance when not in use
2. Use Spot instances for batch jobs
3. Consider reserved instances for long-term

---

## ğŸ”§ Key Features

- âœ… **REST API**: Flask API returns JSON for easy frontend integration
- âœ… **Dual Pipeline**: Baseline and Hybrid modes initialized once
- âœ… **Modular Design**: Easy to modify and extend
- âœ… **Docker-First**: Consistent environment everywhere
- âœ… **GPU Optimized**: 4-bit quantization for efficiency
- âœ… **Production Ready**: Error handling, logging, validation
- âœ… **Flexible Filtering**: 10+ filter types supported
- âœ… **JSON Response**: Returns LLM response + structured chunk data
- âœ… **Two Search Modes**: Baseline and Hybrid with reranking
- âœ… **Easy Deployment**: One command build and run

---

## ğŸ“š Documentation Guide

**Start here:**
1. ğŸ“– **QUICKSTART.md** - Get running in 5 minutes
2. ğŸ“‹ **DEPLOYMENT_CHECKLIST.md** - Track your progress
3. ğŸ“˜ **EC2_SETUP.md** - Detailed setup instructions
4. ğŸ“• **README.md** - Complete reference

---

## ğŸ”Œ Integration with Streamlit

Your pipeline exposes a Flask REST API that returns JSON data for frontend consumption:

```python
# In your Streamlit app
import requests
import pandas as pd
import streamlit as st

# API endpoint (EC2 public IP or localhost)
API_URL = "http://your-ec2-ip:8000"

def run_rag_query(query, filters, mode="hybrid"):
    """Call RAG API and return results."""
    response = requests.post(
        f"{API_URL}/query",
        json={
            "query": query,
            "filters": filters,
            "mode": mode
        },
        timeout=300
    )

    if response.status_code == 200:
        return response.json()
    else:
        st.error(f"Error: {response.status_code}")
        return None

# In Streamlit UI
query = st.text_input("Enter your query")
mode = st.radio("Mode", ["hybrid", "baseline"])

if st.button("Search"):
    result = run_rag_query(query, {}, mode=mode)

    if result:
        # Display LLM response
        st.subheader("AI Response")
        st.write(result["response"])

        # Display retrieved chunks as dataframe
        st.subheader("Retrieved Documents")
        df = pd.DataFrame(result["chunks"])
        st.dataframe(df)

        # Download as CSV (client-side conversion)
        csv = df.to_csv(index=False)
        st.download_button("Download CSV", csv, "results.csv")
```

**API Response Format:**
```json
{
  "response": "LLM-generated answer...",
  "chunks": [
    {
      "id": "chunk_123",
      "score": 0.85,
      "rerank_score": 0.92,
      "state": "ca",
      "county": "alameda-county",
      "chunk_text": "Full legal text...",
      ...
    }
  ],
  "mode": "hybrid"
}
```

---

## ğŸ¯ Next Steps

1. **Deploy to EC2** - Follow QUICKSTART.md
2. **Test with Your Data** - Run example queries
3. **Integrate with Frontend** - Connect to Streamlit
4. **Scale as Needed** - Add more instances or move to ECS
5. **Monitor Costs** - Set up billing alerts

---

## âœ… What Makes This Production-Ready

- âœ… Environment variable configuration
- âœ… Error handling throughout
- âœ… Docker containerization
- âœ… GPU optimization
- âœ… Modular, testable code
- âœ… Comprehensive documentation
- âœ… Deployment automation
- âœ… Volume mounts for persistence
- âœ… Multiple usage modes
- âœ… CSV export for integration

---

## ğŸ¤ Support

**For Issues:**
1. Check troubleshooting in EC2_SETUP.md
2. Review container logs: `docker compose logs -f`
3. Verify GPU access: `nvidia-smi`
4. Check API keys in .env

**Resources:**
- AWS EC2 Documentation
- Docker Documentation  
- Pinecone Documentation
- Hugging Face Hub

---

## ğŸ“ Version Info

- **Pipeline Version**: 1.0.0
- **LLM Model**: meta-llama/Llama-3.1-8B-Instruct
- **Embedding**: Pinecone llama-text-embed-v2 + sparse
- **Reranker**: cross-encoder/ms-marco-MiniLM-L-6-v2
- **Python**: 3.10+
- **CUDA**: 12.1+
- **Docker**: 20.10+

---

**Ready to deploy? Start with QUICKSTART.md! ğŸš€**
